{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ea4ea8d",
   "metadata": {},
   "source": [
    "# EnKF equation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7b4a6e",
   "metadata": {},
   "source": [
    "We will now analyze how Data Assimilation (DA) through the EnKF combines model and observation information. See lecture \"Introduction to Data Assimilation\" for more information on the EnKF equation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0706c4f3",
   "metadata": {},
   "source": [
    "## Setting up the DA run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb06595",
   "metadata": {},
   "source": [
    "The DA run is built upon an ensemble run, as the ensemble information will be used to compute the uncertainty of the model. **Please copy-paste the missing lines from Exercise 2.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8a1b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define parameter K\n",
    "############ TO BE FILLED ##################\n",
    "\n",
    "# Define timestep\n",
    "############ TO BE FILLED ##################\n",
    "\n",
    "# precipitation data\n",
    "############ TO BE FILLED ##################\n",
    "\n",
    "# initialize storage vector\n",
    "############ TO BE FILLED ##################\n",
    "\n",
    "# Define ensemble size\n",
    "############ TO BE FILLED ##################\n",
    "\n",
    "# Load gaussian noise files\n",
    "############ TO BE FILLED ##################\n",
    "\n",
    "# Set noise amplitude\n",
    "############ TO BE FILLED ##################\n",
    "\n",
    "# Perturb variables\n",
    "############ TO BE FILLED ##################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991bed54",
   "metadata": {},
   "source": [
    "We will now continue setting up the Data Assimilation run. First, we need to get some observations. In this case, as this bucket model is a ficticious scenario, we will generate synthetic water storage observations. For that purpose, we start by generating a synthetic ground truth:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf7b1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import linearModel\n",
    "\n",
    "# %% Generate synthetic ground truth\n",
    "sim = np.array([0, 23])  # Python is 0-indexed\n",
    "S0_true = 8\n",
    "S_true = np.zeros(sim[1] - sim[0] + 1)\n",
    "S_true[0] = S0_true\n",
    "Q_true, S_true = linearModel.linearModel(S_true, P[sim[0]:sim[1] + 1], K, Dt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820d2704",
   "metadata": {},
   "source": [
    "We will now generate the observations, which represent a noisy measurement of this synthetic truth. **[Marker for extra exercises].**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58980ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Generate observations\n",
    "noise_S_obs = np.load('data/noise_S_obs.npy')\n",
    "sigma_sObs = 0.3\n",
    "offset = 0\n",
    "S_obs = S_true + offset + S_true * sigma_sObs * noise_S_obs.T[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ebfa04",
   "metadata": {},
   "source": [
    "Now that the observations are generated, we will perturb them to then assimilate them throught the EnKF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a510d458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perturb observations\n",
    "Y = np.tile(S_obs[:, np.newaxis], (1, Ne))\n",
    "noise_dY = np.load('data/noise_dY.npy')\n",
    "dY = np.tile(S_true[:, np.newaxis], (1, Ne)) * sigma_sObs * noise_dY\n",
    "Y_ens = Y + dY\n",
    "Y_ens[Y_ens < 0] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1198c2a6",
   "metadata": {},
   "source": [
    "Another variable we need for the DA run is the design matrix, which relates the model state to the observed variable. In this case, the relation is 1-to-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa54a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Design matrix\n",
    "A = np.array([[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e58811",
   "metadata": {},
   "source": [
    "## Initialization run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f63b5a",
   "metadata": {},
   "source": [
    "We will now intialize the model over a period of 12 timesteps. **Can you copy-paste the missing lines from Exercise 2?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d3e8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Initialization run\n",
    "############ TO BE FILLED ##################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fa1c5c",
   "metadata": {},
   "source": [
    "## Open Loop run (Ensemble run)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f25524",
   "metadata": {},
   "source": [
    "We will also run the ensemble run as done in the previous exercise, so that we can plot it and copare it with the DA results. In the field of land DA, this is often referred to as \"Open Loop (OL)\" run. **Please copy-paste the missing lines from Exercise 2.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86eaf81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Open Loop run\n",
    "############ TO BE FILLED ##################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbc49b9",
   "metadata": {},
   "source": [
    "## Data Assimilation run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90e11e8",
   "metadata": {},
   "source": [
    "We finally launch the DA run. First, let us initialize the variables that we will be using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28b5d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# % Initialization\n",
    "S_t = S0_ens.copy()\n",
    "n_steps = sim[1] - sim[0] + 1\n",
    "\n",
    "xMinus_3d = np.zeros((1, Ne, n_steps))\n",
    "xPlus_3d = np.zeros_like(xMinus_3d)\n",
    "Cxx_3d = np.zeros((1, 1, n_steps))\n",
    "Cxpxp_3d = np.zeros_like(Cxx_3d)\n",
    "Sll_2d = np.zeros((n_steps, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12c434b",
   "metadata": {},
   "source": [
    "During DA, we will iterate over the timesteps combining two steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58ff55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# % loop over time\n",
    "for t in range(sim[0], sim[1] + 1):\n",
    "#   % Step 1: forward model run\n",
    "#   % in this step, we will run the model forward of one timestep for all of the \n",
    "#   % ensemble members:\n",
    "    Q_tp1 = np.zeros((1, Ne))\n",
    "    S_tp1 = np.zeros((1, Ne))\n",
    "    for ii in range(Ne):\n",
    "        Q_tp1[0, ii], S_tp1[0, ii] = linearModel.linearModel(\n",
    "            np.array([S_t[0,ii]]),\n",
    "            np.array([P_ens[t, ii]]),\n",
    "            K_ens[0,ii],\n",
    "            Dt\n",
    "        )\n",
    "\n",
    "#   % Step 2: DA update\n",
    "#   % In this step, we will update the model state using the observations as well \n",
    "#   % as model and observation uncertainties. First, we will add the model state in \n",
    "#   % the vector xMinus. We can then use this information to compute the empirical \n",
    "#   % error covariance matrix of the model state.\n",
    "    \n",
    "    # model prediction vector\n",
    "    xMinus = S_tp1.copy()\n",
    "    # empirical model error covariance matrix\n",
    "    Cxx = (1 / (Ne - 1)) * (xMinus - np.mean(xMinus, axis=1, keepdims=True)) @ \\\n",
    "          (xMinus - np.mean(xMinus, axis=1, keepdims=True)).T\n",
    "    \n",
    "\n",
    "#   % Similarly, we will use the observation perturbations to compute the error \n",
    "#   % covariance matrix of the observations:\n",
    "\n",
    "    # % empirical observation error covariance matrix\n",
    "    Sll = (1 / (Ne - 1)) * dY[t, :] @ dY[t, :].T\n",
    "\n",
    "#   % We now have sufficient information to fill the Kalman gain. \n",
    "#   % Please add the Kalman gain equation. You will have to use the \n",
    "#   % function np.linalg.inv to compute the inverse of matrices.\n",
    "\n",
    "    # Kalman gain\n",
    "    ############ TO BE FILLED ##################\n",
    "\n",
    "#   % We can now apply the EnKF update to the model state stored in xMinus, \n",
    "#   % thus generating xPlus.\n",
    "\n",
    "    # Kalman update\n",
    "    xPlus = xMinus + K_gain[0,0] * (Y_ens[t, :] - (A @ xMinus).flatten())\n",
    "\n",
    "#   % We can now initialize the next run with the updated information\n",
    "\n",
    "    # Re-initialize\n",
    "    S_t = xPlus\n",
    "\n",
    "#   % Before we go forward, we will save all the update information in the preset \n",
    "#   % matrices, so that we can plot them after the process is done.\n",
    "\n",
    "    # Save stats\n",
    "    Cxpxp = (1 / (Ne - 1)) * (xPlus - np.mean(xPlus, axis=1, keepdims=True)) @ \\\n",
    "            (xPlus - np.mean(xPlus, axis=1, keepdims=True)).T\n",
    "\n",
    "    idx = t - sim[0]\n",
    "    xMinus_3d[:, :, idx] = xMinus\n",
    "    xPlus_3d[:, :, idx] = xPlus\n",
    "    Cxx_3d[:, :, idx] = Cxx\n",
    "    Cxpxp_3d[:, :, idx] = Cxpxp\n",
    "    Sll_2d[idx, 0] = Sll"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe80821",
   "metadata": {},
   "source": [
    "## Visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b8ca8f",
   "metadata": {},
   "source": [
    "Let us visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64a6e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions.Visualization_functions import F_Visualize_Ex3\n",
    "\n",
    "# %% Visualization\n",
    "F_Visualize_Ex3.F_Visualize_Ex3(Y_ens, S_obs, S_true, S_ens, xPlus_3d, Sll_2d, Cxx_3d, Cxpxp_3d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48005ede",
   "metadata": {},
   "source": [
    "## Extra exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad819025",
   "metadata": {},
   "source": [
    "- Go to the [Marker for extra exercises] and triple the observation uncertainties (that is, triple the variable sigma_sObs). Then run the whole script again, and see what happens.\n",
    "- Now, make the observation uncertainty 3 times smaller. Run the whole script again and see what happens. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c747e4a",
   "metadata": {},
   "source": [
    "## Reflection questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd2245d",
   "metadata": {},
   "source": [
    "1. Do you think the observation and their uncertainty is realistic, given the ground truth? \n",
    "\n",
    "The ground truth lays within the ensemble of observations. Therefore, it can be considered a pretty realistic uncertainty (maybe slightly overestimated). \n",
    "\n",
    "2. What happens to the model estimates in the DA process? \n",
    "\n",
    "Model estimates pushed towards the observations and the truth. \n",
    "\n",
    "3. What happens to the model uncertainties in the DA process? \n",
    "\n",
    "The uncertainty levels are reduced. The uncertainty of DA is smaller than that of the OL and that of the observations. \n",
    "\n",
    "4. What do you think is the benefit of DA for models? \n",
    "\n",
    "Increased realism of the model while accounting for the uncertainties of both model and observations.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
